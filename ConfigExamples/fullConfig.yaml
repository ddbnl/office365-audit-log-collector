log:  # Log settings. Debug will severely decrease performance
  path: 'collector.log'
  debug: False
collect:  # Settings determining which audit logs to collect and how to do it
  workingDir: ./ # Directory to save cache files in (known_logs, known_content, last_run). Default is dir where executable is located
  contentTypes:
    Audit.General: True
    Audit.AzureActiveDirectory: True
    Audit.Exchange: True
    Audit.SharePoint: True
    DLP.All: True
  cacheSize: 500000  # Amount of logs to cache/batch until outputting, larger=faster but eats more memory
  maxThreads: 50  # Maximum number of simultaneous threads retrieving logs
  globalTimeout: 0  # Number of minutes before the process is forced to exit if still running (0 = no timeout). If you run e.g. every hour you could set this to 59, ensuring there will only be 1 active process.
  retries: 3  # Times to retry retrieving a content blob if it fails
  retryCooldown: 3  # Seconds to wait before retrying retrieving a content blob
  autoSubscribe: True  # Automatically subscribe to collected content types. Never unsubscribes from anything.
  skipKnownLogs: True  # Remember retrieved log ID's, don't collect them twice
  hoursToCollect: 24  # Look back this many hours for audit logs (can be overwritten by resume)
  filter:  # Only logs that match ALL filters for a content type are collected. Leave empty to collect all
    Audit.General:
    Audit.AzureActiveDirectory:
    Audit.Exchange:
    Audit.SharePoint:
    DLP.All:
output:
  file:  # CSV output
    enabled: False
    separateByContentType: True  # Creates a separate CSV file for each content type, using file name from 'path' as a prefix
    path: 'output.csv'
    separator: ';'
  azureLogAnalytics:
    enabled: False
    workspaceId:
    sharedKey:
    maxThreads: 50  # Maximum simultaneous threads sending logs to workspace
  azureTable:  # Provide connection string to executable at runtime with --table-string
    enabled: False
    tableName: AuditLogs  # Name of the table inside the storage account
    maxThreads: 10  # Maximum simultaneous threads sending logs to Table
  azureBlob:  # Write CSV to a blob container. Provide connection string to executable at runtime with --blob-string
    enabled: False
    containerName: AuditLogs  # Name of the container inside storage account
    blobName: AuditLog  # When separatedByContentType is true, this is used as file prefix and becomes e.g. AuditLog_AuditExchange.csv
    tempPath: './output'
    separateByContentType: True
    separator: ';'
    cacheSize: 500000  # Amount of logs to cache until each CSV commit, larger=faster but eats more memory
  sql:  # Provide connection string to executable at runtime with --sql-string
    enabled: False
    cacheSize: 500000  # Amount of logs to cache until each SQL commit, larger=faster but eats more memory
    chunkSize: 2000  # Amount of rows to write simultaneously to SQL, in most cases just set it as high as your DB allows. COUNT errors = too high
  graylog:
    enabled: False
    address:
    port:
  prtg:
    enabled: False
    channels:
  fluentd:
    enabled: True
    tenantName:
    address:
    port:
